{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179f9ce7",
   "metadata": {},
   "source": [
    "# 一、基础深度学习：张量操作与模型构建\n",
    "## 题目 1：张量运算与自动求导（PyTorch/TensorFlow）\n",
    "任务：\n",
    "\n",
    "用 PyTorch 或 TensorFlow 创建随机张量（形状 3x4），执行矩阵乘法、转置、归一化操作。\n",
    "\n",
    "定义计算图：y = 2x² + 3x + 5，其中x是可训练张量，计算y对x的梯度。\n",
    "\n",
    "用自动求导机制求解当x=[1,2,3]时的梯度值，并验证解析解（导数4x+3）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08684d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb5e170",
   "metadata": {},
   "source": [
    "# 二、计算机视觉（CNN 核心）\n",
    "## 题目 2：MNIST 手写识别（基础 CNN）\n",
    "数据：MNIST 数据集（28x28 灰度图像，10 分类）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建 CNN 模型：\n",
    "\n",
    "    卷积层：16 个 3x3 滤波器，ReLU 激活，步长 1，填充'same'\n",
    "\n",
    "    最大池化层：2x2 窗口\n",
    "\n",
    "    展平层 + 全连接层：128 神经元，Dropout 率 0.2\n",
    "\n",
    "    输出层：10 神经元，Softmax\n",
    "\n",
    "2.使用混合精度训练加速，记录训练耗时与显存占用。\n",
    "\n",
    "3.在测试集上达到≥99% 准确率，可视化 5 个最难分类样本的特征图（用中间卷积层输出）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db1974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5cb354",
   "metadata": {},
   "source": [
    "## 题目 3：图像分割（U-Net）\n",
    "数据：CamVid 道路分割数据集（或 Kaggle 的语义分割数据集）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.实现 U-Net 架构：\n",
    "\n",
    "    编码器：4 层卷积 + 池化（通道数 32→64→128→256）\n",
    "\n",
    "    解码器：4 层转置卷积 + 跳跃连接（通道数 256→128→64→32）\n",
    "\n",
    "    输出层：1 通道，Sigmoid 激活（二分类）或多通道 Softmax（多分类）\n",
    "\n",
    "2.使用 Dice 损失函数处理类别不平衡，搭配 AdamW 优化器。\n",
    "\n",
    "3.可视化预测结果与真实掩码的对比，计算交并比（IoU）和像素准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c2542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55d0ed64",
   "metadata": {},
   "source": [
    "# 三、自然语言处理（NLP）\n",
    "## 题目 4：文本分类（TransformerEncoder）\n",
    "数据：IMDB 影评数据集（正负情感分类）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.用 Hugging Face 的Tokenizers库预处理文本，构建词表（Vocab）并截断到长度 512。\n",
    "\n",
    "2.自定义 Transformer 编码器模型：\n",
    "\n",
    "    嵌入层：词嵌入 + 位置编码（维度 300）\n",
    "\n",
    "    多头自注意力层：8 头，隐藏维度 300\n",
    "\n",
    "    前馈网络：2 层（300→600→300），Dropout 率 0.1\n",
    "\n",
    "    分类层：1 神经元，Sigmoid 激活\n",
    "\n",
    "3.对比该模型与 LSTM 模型的训练速度和 AUC-ROC 曲线，分析自注意力机制的优势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8a407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b36d8a",
   "metadata": {},
   "source": [
    "## 题目 5：机器翻译（Seq2Seq + 注意力）\n",
    "数据：WMT 英德翻译数据集（可通过torchtext加载）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建 Encoder-Decoder 架构：\n",
    "\n",
    "    编码器：双向 GRU，隐藏维度 512\n",
    "\n",
    "    解码器：带 Bahdanau 注意力的 GRU，输出层使用 Teacher Forcing\n",
    "\n",
    "2.实现束搜索（Beam Search）解码，优化翻译流畅度。\n",
    "\n",
    "3.用 BLEU 分数评估翻译质量，对比贪心解码与束搜索的结果差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a30b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36f9f41a",
   "metadata": {},
   "source": [
    "# 四、序列建模与时空数据\n",
    "题目 6：时间序列预测（Temporal Fusion Transformer）\n",
    "\n",
    "数据：电力负荷预测数据集（或合成多变量时间序列）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.使用 TFT 模型（Google提出的时序预测模型）处理多变量输入：\n",
    "\n",
    "    处理静态特征（如地理位置）、周期特征（如星期、小时）\n",
    "\n",
    "    构建分层注意力机制，捕捉短期和长期依赖\n",
    "\n",
    "2.用 MASE（Mean Absolute Scaled Error）和 SMAPE 评估预测误差。\n",
    "\n",
    "3.可视化某时间点的注意力权重，分析模型关注的关键特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a2205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "509af844",
   "metadata": {},
   "source": [
    "## 题目 7：视频动作识别（3D CNN）\n",
    "数据：UCF101 视频数据集（101 类动作，如跑步、挥手）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建 C3D（Convolutional 3D）网络：\n",
    "\n",
    "    3D 卷积层：16 个 3x3x3 滤波器，步长 1x1x1\n",
    "\n",
    "    3D 池化层：2x2x2 窗口，步长 2x2x2\n",
    "\n",
    "    全局平均池化 + 全连接层：分类输出\n",
    "\n",
    "2.使用光流（Optical Flow）增强模型对运动的捕捉能力，对比仅用 RGB 帧的准确率。\n",
    "\n",
    "3.实现视频片段采样策略（如均匀采样 16 帧），优化计算效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a10bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c93d5b90",
   "metadata": {},
   "source": [
    "# 五、生成模型与无监督学习\n",
    "## 题目 8：变分自动编码器（VAE）\n",
    "数据：Fashion-MNIST 数据集（服装图像生成）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建 VAE 模型：\n",
    "\n",
    "    编码器：2 层全连接，输出均值和对数方差（ latent 维度 10）\n",
    "\n",
    "    解码器：2 层全连接，转置卷积还原图像\n",
    "\n",
    "    损失函数：重构损失（MSE）+ KL 散度正则项\n",
    "\n",
    "2.在潜在空间中进行插值（Interpolation），生成中间状态的图像。\n",
    "\n",
    "3.计算生成图像的 FID（Frechet Inception Distance）分数，评估质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da36abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9d5bdb8",
   "metadata": {},
   "source": [
    "## 题目 9：扩散模型（DDPM）\n",
    "数据：CelebA 人脸数据集（64x64 像素）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.实现 DDPM（Denoising Diffusion Probabilistic Models）的前向扩散和反向采样过程：\n",
    "\n",
    "    定义 β schedule（如线性增长或余弦退火）\n",
    "\n",
    "    构建 UNet 作为去噪网络，输入含噪声图像和时间步嵌入\n",
    "\n",
    "2.训练模型并可视化不同采样步数（如 100 步、500 步）的生成效果。\n",
    "\n",
    "3.对比 GAN 和扩散模型在生成多样性和真实性上的差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51b36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e3706a",
   "metadata": {},
   "source": [
    "# 六、多模态与自监督学习\n",
    "## 题目 10：图文检索（CLIP 模型微调）\n",
    "数据：Flickr30K 图像文本对数据集。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.加载预训练的 CLIP 模型（如 ViT-B/32），冻结图像编码器和文本编码器。\n",
    "\n",
    "2.构建对比学习损失函数，优化图文匹配的余弦相似度。\n",
    "\n",
    "3.实现图像 - 文本检索功能：输入文本查询，返回最相关的图像（用余弦距离排序）。\n",
    "\n",
    "4.可视化图文特征在潜在空间中的分布（用 t-SNE 降维）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4b128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c9bc4e0",
   "metadata": {},
   "source": [
    "## 题目 11：自监督学习（SimCLR）\n",
    "数据：CIFAR-10 数据集（无标签图像）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.实现 SimCLR 框架：\n",
    "\n",
    "    数据增强：随机裁剪、颜色抖动、高斯模糊\n",
    "\n",
    "    图像编码器：ResNet-18，输出 2048 维特征\n",
    "\n",
    "    投影头：2 层 MLP，将特征映射到对比空间\n",
    "\n",
    "    对比损失：最大化同一图像不同视图的特征相似度，最小化不同图像的相似度\n",
    "\n",
    "2.预训练模型后，在下游分类任务（线性评估）上测试准确率。\n",
    "\n",
    "3.分析不同数据增强组合对预训练效果的影响（如仅裁剪 vs 裁剪 + 颜色抖动）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb01d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c12cba6",
   "metadata": {},
   "source": [
    "# 七、模型优化与工程实践\n",
    "## 题目 12：模型量化与部署（TensorRT 加速）\n",
    "\n",
    "数据：已训练好的 ResNet-50 图像分类模型（PyTorch 或 TensorFlow）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.使用 FP16 或 INT8 量化压缩模型，对比量化前后的模型大小和推理延迟。\n",
    "\n",
    "2.将模型转换为 TensorRT 引擎，在NVIDIA GPU 上测试吞吐量提升倍数。\n",
    "\n",
    "3.用 ONNX 格式导出模型，部署到 Python Flask 服务，实现 HTTP 图像分类接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bbbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ad093b0",
   "metadata": {},
   "source": [
    "## 题目 13：可解释性分析（SHAP 与 Grad-CAM）\n",
    "数据：任意图像分类模型（如 ResNet-18 在 CIFAR-10 上的模型）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.用 SHAP 值分析某图像的预测结果，识别对类别决策贡献最大的前 5 个特征（如像素区域）。\n",
    "\n",
    "2.使用 Grad-CAM 生成类激活图，可视化模型关注的图像区域是否符合语义（如 “飞机” 类别应关注机翼）。\n",
    "\n",
    "3.对比两种方法的解释结果，撰写可解释性报告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef24473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d344a4",
   "metadata": {},
   "source": [
    "# 八、前沿方向（选做）\n",
    "## 题目 14：神经辐射场（NeRF）\n",
    "数据：LLFF 数据集（如 Fortress 场景的多角度图像）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.实现基础 NeRF 模型：\n",
    "\n",
    "    位置编码：将 3D 坐标和视角方向映射到高频空间\n",
    "\n",
    "    MLP 网络：预测体密度和辐射度，使用体积渲染合成图像\n",
    "\n",
    "2.优化训练流程：引入层次化采样（Hierarchical Sampling）减少计算量。\n",
    "\n",
    "3.可视化渲染的新视角图像，对比原始图像的 PSNR 值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce52bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22523579",
   "metadata": {},
   "source": [
    "## 题目 15：强化学习（深度强化学习）\n",
    "环境：gym库的CarRacing-v2驾驶环境。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.实现 DQN 算法：\n",
    "\n",
    "    构建 CNN 作为 Q 网络，输入连续 4 帧图像，输出动作值\n",
    "\n",
    "    使用经验回放缓冲区和目标网络稳定训练\n",
    "\n",
    "2.训练智能体完成赛道驾驶，记录平均奖励随 episode 的变化曲线。\n",
    "\n",
    "3.尝试升级为 PPO 算法（策略梯度方法），对比离散动作空间与连续动作空间的处理差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b088f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
