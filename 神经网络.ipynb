{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d3cae5",
   "metadata": {},
   "source": [
    "# 一、基础神经网络：全连接层（MLP）\n",
    "## 题目 1：手写数字分类（全连接神经网络）\n",
    "数据：MNIST 数据集（6 万训练样本，1 万测试样本，28x28 灰度图像）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.加载数据并预处理：将像素值归一化到 [0,1]，标签转为独热编码。\n",
    "\n",
    "2.构建 2 层全连接神经网络：\n",
    "\n",
    "    输入层：784 维（展平的图像）\n",
    "\n",
    "    隐藏层：128 个神经元，激活函数 ReLU\n",
    "\n",
    "    输出层：10 个神经元，激活函数 Softmax\n",
    "\n",
    "3.编译模型：使用 Adam 优化器，损失函数sparse_categorical_crossentropy。\n",
    "\n",
    "4.训练模型：迭代 20 轮，批次大小 32，记录训练集与验证集损失曲线。\n",
    "\n",
    "5.在测试集上评估准确率，可视化 5 个错误预测样本及其真实标签与预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceecc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "286cdd94",
   "metadata": {},
   "source": [
    "# 二、卷积神经网络（CNN）\n",
    "## 题目 2：CIFAR-10 图像分类（基础 CNN）\n",
    "数据：CIFAR-10 数据集（5 万训练样本，1 万测试样本，32x32 彩色图像，10 类）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建 CNN 架构：\n",
    "\n",
    "    卷积层 1：32 个 3x3 滤波器，ReLU 激活，填充'same'\n",
    "\n",
    "    最大池化层：2x2 池化窗口\n",
    "\n",
    "    卷积层 2：64 个 3x3 滤波器，ReLU 激活\n",
    "\n",
    "    最大池化层：2x2 池化窗口\n",
    "\n",
    "    展平层 + 全连接层：512 个神经元，ReLU 激活，Dropout 率 0.5\n",
    "\n",
    "    输出层：10 个神经元，Softmax 激活\n",
    "\n",
    "2.使用数据增强（旋转、缩放、水平翻转）提升泛化能力。\n",
    "\n",
    "3.训练模型并绘制学习曲线，对比有无数据增强的验证集准确率差异。\n",
    "\n",
    "4.用 Grad-CAM 可视化某图像的关键特征区域（提示：用keras-vis库）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9094379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76fa6470",
   "metadata": {},
   "source": [
    "## 题目 3：迁移学习（VGG16 微调）\n",
    "数据：自定义图像数据集（如猫狗分类，可从 Kaggle 获取）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.加载预训练的 VGG16 模型（不含顶层），冻结前 10 层卷积层。\n",
    "\n",
    "2.添加自定义分类头：全局平均池化层 + 全连接层（256 神经元，ReLU） + 输出层（2 神经元，Softmax）。\n",
    "\n",
    "3.编译模型：使用 SGD 优化器（学习率 0.001），损失函数binary_crossentropy。\n",
    "\n",
    "4.分阶段训练：先训练分类头，再解冻部分卷积层进行微调。\n",
    "\n",
    "5.对比迁移学习与从头训练的模型在测试集上的准确率与收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcccd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4aba88a",
   "metadata": {},
   "source": [
    "# 三、循环神经网络（RNN/LSTM）\n",
    "## 题目 4：IMDB 影评情感分类（LSTM 网络）\n",
    "数据：IMDB 影评数据集（2.5 万训练样本，2.5 万测试样本，正负向情感标签）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.文本预处理：\n",
    "\n",
    "    用Tokenizer将文本转为序列，保留前 10000 个高频词。\n",
    "\n",
    "    截断 / 填充序列到固定长度（如 200）。\n",
    "\n",
    "2.构建 LSTM 模型：\n",
    "\n",
    "    嵌入层：100 维词向量\n",
    "\n",
    "    LSTM 层：128 个神经元，返回序列 = False\n",
    "\n",
    "    全连接层：64 神经元，ReLU 激活，Dropout 率 0.3\n",
    "\n",
    "    输出层：1 神经元，Sigmoid 激活\n",
    "\n",
    "3.训练模型并绘制精确率 - 召回率曲线（PR 曲线），计算 AUPRC。\n",
    "\n",
    "4.尝试用双向 LSTM（Bidirectional LSTM）提升性能，对比单向 LSTM 的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c0f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddf60112",
   "metadata": {},
   "source": [
    "## 题目 5：时间序列预测（GRU 网络）\n",
    "数据：Numenta 公司的 NASA 轴承故障数据集（或合成正弦波序列）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建时间序列样本：将序列分割为输入窗口（如前 50 步）和输出标签（后 1 步）。\n",
    "\n",
    "2.设计 GRU 模型：\n",
    "\n",
    "    输入层：形状为（窗口长度，特征数）\n",
    "\n",
    "    GRU 层：64 个神经元，返回序列 = False\n",
    "\n",
    "    全连接层：1 个神经元（回归预测）\n",
    "\n",
    "3.使用均方根误差（RMSE）评估模型，绘制真实值与预测值的对比曲线。\n",
    "\n",
    "4.尝试添加注意力机制（如 Additive Attention）到模型中，观察预测误差变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d5624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0c607f",
   "metadata": {},
   "source": [
    "# 四、高级神经网络架构\n",
    "## 题目 6：Transformer 文本分类（自注意力机制）\n",
    "数据：AG 新闻数据集（4 类文本分类，可通过 Hugging Face 加载）。\n",
    "\n",
    "任务：\n",
    "\n",
    "使用预训练的 BERT 分词器（如bert-base-uncased）处理文本。\n",
    "\n",
    "构建基于 Transformer 的分类模型：\n",
    "\n",
    "输入层：Token IDs + 段嵌入 + 位置嵌入\n",
    "\n",
    "多头自注意力层：8 头，隐藏维度 512\n",
    "\n",
    "前馈神经网络层：2 层（512→256）\n",
    "\n",
    "分类层：4 神经元，Softmax 激活\n",
    "\n",
    "用预训练权重初始化模型，在 AG 新闻数据集上微调。\n",
    "\n",
    "对比传统 LSTM 与 Transformer 模型的推理速度和分类准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81479dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7f1b6b",
   "metadata": {},
   "source": [
    "## 题目 7：生成对抗网络（GAN）\n",
    "数据：Fashion-MNIST 数据集（6 万张服装图像，28x28 灰度）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.构建生成器（Generator）：\n",
    "\n",
    "    输入：100 维噪声向量\n",
    "\n",
    "    层：转置卷积层逐步上采样至 28x28，激活函数 Tanh\n",
    "\n",
    "2.构建判别器（Discriminator）：\n",
    "\n",
    "    输入：28x28 图像，层：卷积层提取特征，输出 1 维概率（Sigmoid 激活）\n",
    "\n",
    "3.联合训练 GAN：\n",
    "\n",
    "    交替优化生成器和判别器，使用二元交叉熵损失。\n",
    "\n",
    "    记录训练过程中判别器对真实 / 生成样本的概率值变化。\n",
    "\n",
    "4.训练完成后，生成 10 张服装图像并可视化，评估生成质量（可对比 FID 分数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d43d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba30a140",
   "metadata": {},
   "source": [
    "# 五、神经网络优化与解释\n",
    "## 题目 8：模型压缩与量化（剪枝与低精度训练）\n",
    "数据：已训练好的 MNIST 分类模型（全连接网络）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.使用 Keras 剪枝 API（pruning）对模型进行结构化剪枝（如裁剪 50% 的连接）。\n",
    "\n",
    "2.对剪枝后的模型进行微调，对比剪枝前后的参数量和测试准确率。\n",
    "\n",
    "3.将模型权重从 32 位浮点数量化为 8 位整数，使用 TensorFlow Lite 部署。\n",
    "\n",
    "4.在移动设备（或模拟器）上测试量化模型的推理速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27d2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "691e1dc6",
   "metadata": {},
   "source": [
    "## 题目 9：神经网络可解释性（SHAP 值与 LIME）\n",
    "数据：CIFAR-10 分类模型（CNN）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.用 SHAP（SHapley Additive exPlanations）分析某图像的预测结果，识别对类别决策贡献最大的像素区域。\n",
    "\n",
    "2.使用 LIME（Local Interpretable Model-agnostic Explanations）解释模型对单个样本的预测逻辑。\n",
    "\n",
    "3.可视化 SHAP 值热力图和 LIME 的特征重要性排名，撰写分析报告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aaf978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac2a686a",
   "metadata": {},
   "source": [
    "# 六、前沿方向（选做）\n",
    "## 题目 10：神经辐射场（NeRF）三维重建\n",
    "数据：自定义物体多角度图像数据集（或使用合成数据集）。\n",
    "\n",
    "任务：\n",
    "\n",
    "1.实现基础 NeRF 模型：\n",
    "\n",
    "    位置编码（Positional Encoding）将坐标映射到高维空间。\n",
    "\n",
    "    多层感知机（MLP）预测体密度和辐射度。\n",
    "\n",
    "    使用体积渲染（Volume Rendering）合成渲染图像。\n",
    "\n",
    "2.训练模型拟合场景，可视化重建的 3D 模型和渲染图像。\n",
    "\n",
    "3.尝试优化：引入余弦退火学习率衰减，或使用多尺度采样提升渲染效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa6d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
